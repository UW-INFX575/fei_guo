{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lda\n",
    "import lda.datasets\n",
    "from __future__ import division, print_function\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA for the 10 documents provided by Jevin\n",
    "\n",
    "#http://stackoverflow.com/questions/15899861/efficient-term-document-matrix-with-nltk\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "def fn_tdm_df(docs, xColNames = None, **kwargs):\n",
    "    ''' create a term document matrix as pandas DataFrame\n",
    "    with **kwargs you can pass arguments of CountVectorizer\n",
    "    if xColNames is given the dataframe gets columns Names'''\n",
    "\n",
    "    #initialize the  vectorizer\n",
    "    vectorizer = CountVectorizer(**kwargs)\n",
    "    x1 = vectorizer.fit_transform(docs)\n",
    "    #create dataFrame\n",
    "    df = pd.DataFrame(x1.toarray().transpose(), index = vectorizer.get_feature_names())\n",
    "    if xColNames is not None:\n",
    "        df.columns = xColNames\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIR = '/Users/feismacbookpro/Desktop/INFX575/HW3/docs/'\n",
    "\n",
    "def fn_CorpusFromDIR(xDIR):\n",
    "    ''' functions to create corpus from a Directories\n",
    "    Input: Directory\n",
    "    Output: A dictionary with \n",
    "             Names of files ['ColNames']\n",
    "             the text in corpus ['docs']'''\n",
    "    import os\n",
    "    Res = dict(docs = [open(os.path.join(xDIR,f)).read() for f in os.listdir(xDIR)],\n",
    "               ColNames = map(lambda x: x[0:], os.listdir(xDIR)))\n",
    "    return Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/feismacbookpro/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.py:654: DeprecationWarning: The charset_error parameter is deprecated as of version 0.14 and will be removed in 0.16. Use decode_error instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "d1 = fn_tdm_df(docs = fn_CorpusFromDIR(DIR)['docs'],\n",
    "          xColNames = fn_CorpusFromDIR(DIR)['ColNames'], \n",
    "          stop_words='english', charset_error = 'replace')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>...</th>\n",
       "      <th>wafer</th>\n",
       "      <th>wall</th>\n",
       "      <th>walls</th>\n",
       "      <th>washed</th>\n",
       "      <th>water</th>\n",
       "      <th>wheels</th>\n",
       "      <th>whereat</th>\n",
       "      <th>whirlpool</th>\n",
       "      <th>width</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.DS_Store</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0</td>\n",
       "      <td>  0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334220.txt</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0</td>\n",
       "      <td>  0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334221.txt</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0</td>\n",
       "      <td>  0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  8</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334222.txt</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0</td>\n",
       "      <td>  0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334223.txt</th>\n",
       "      <td> 5</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0</td>\n",
       "      <td>  0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334224.txt</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0</td>\n",
       "      <td>  3</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 13</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 12</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334225.txt</th>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td>...</td>\n",
       "      <td>  0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 12</td>\n",
       "      <td> 1</td>\n",
       "      <td>  0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td>  0</td>\n",
       "      <td> 7</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334226.txt</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 5</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td>...</td>\n",
       "      <td>  0</td>\n",
       "      <td>  2</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  2</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334227.txt</th>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0</td>\n",
       "      <td> 19</td>\n",
       "      <td>  4</td>\n",
       "      <td> 0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334228.txt</th>\n",
       "      <td> 6</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 2</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>  0</td>\n",
       "      <td>  0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334229.txt</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 5</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 8</td>\n",
       "      <td> 1</td>\n",
       "      <td>...</td>\n",
       "      <td> 14</td>\n",
       "      <td>  0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  4</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             10  11  12  13  14  15  16  17  18  19 ...  wafer  wall  walls  \\\n",
       ".DS_Store     0   0   0   0   0   0   0   0   0   0 ...      0     0      0   \n",
       "6334220.txt   0   0   0   0   0   0   0   0   0   0 ...      0     0      0   \n",
       "6334221.txt   1   1   1   1   2   1   2   2   1   0 ...      0     0      0   \n",
       "6334222.txt   0   0   0   0   0   0   0   0   0   0 ...      0     0      0   \n",
       "6334223.txt   5   2   1   1   2   1   1   0   0   0 ...      0     0      0   \n",
       "6334224.txt   1   1   1   0   0   0   0   0   0   0 ...      0     3      0   \n",
       "6334225.txt   2   1   2   1   2   2   1   2   1   2 ...      0     0     12   \n",
       "6334226.txt   1   1   1   5   2   1   1   1   1   1 ...      0     2      0   \n",
       "6334227.txt   2   1   1   0   0   0   0   0   0   0 ...      0    19      4   \n",
       "6334228.txt   6   1   2   2   2   1   0   0   0   0 ...      0     0      0   \n",
       "6334229.txt   1   1   1   5   1   1   1   1   8   1 ...     14     0      0   \n",
       "\n",
       "             washed  water  wheels  whereat  whirlpool  width  zip  \n",
       ".DS_Store         0      0       0        0          0      0    0  \n",
       "6334220.txt       0      0       0        0          0      0    0  \n",
       "6334221.txt       0      8       0        0          0      0    2  \n",
       "6334222.txt       0      0       0        0          0      0    0  \n",
       "6334223.txt       0      0       0        0          0      2    0  \n",
       "6334224.txt       0     13       0        0         12      0    0  \n",
       "6334225.txt       1      0       2        1          0      7    0  \n",
       "6334226.txt       0      2       0        0          0      0    0  \n",
       "6334227.txt       0      0       0        0          0      0    0  \n",
       "6334228.txt       0      0       0        0          0      0    0  \n",
       "6334229.txt       0      4       0        0          0      0    0  \n",
       "\n",
       "[11 rows x 521 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = d1.T\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#file locations\n",
    "seq = ['6334220.txt','6334221.txt','6334222.txt','6334223.txt','6334224.txt','6334225.txt','6334226.txt','6334227.txt','6334228.txt','6334229.txt']\n",
    "\n",
    "#function to load text\n",
    "def load_data(text_loc):\n",
    "    #load text file and remove stop words, punctuation, and random letters\n",
    "    with open(DIR + text_loc, 'r') as text_file:\n",
    "        text = text_file.read()\n",
    "    return text\n",
    "\n",
    "#make texts into one file\n",
    "text = []\n",
    "for i in range(len(seq)):\n",
    "    text.append(load_data(seq[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make vocab\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def make_vocab(text_loc):\n",
    "    stopset = set(stopwords.words('english')) #make stop words\n",
    "    exclude = set(string.punctuation) #save punctuations\n",
    "\n",
    "    #load text file and remove stop words, punctuation, and random letters\n",
    "    with open(text_loc, 'r') as text_file:\n",
    "        text = text_file.read()\n",
    "        tokens = word_tokenize(str(text))\n",
    "        tokens = [w for w in tokens if not w in stopset]\n",
    "        tokens = [w for w in tokens if not w in exclude]  #http://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string-in-python\n",
    "        tokens = [w for w in tokens if len(w)>2] #http://stackoverflow.com/questions/24332025/remove-words-of-length-less-than-4-from-string\n",
    "        tokens = list(set(tokens))\n",
    "    return tokens\n",
    "\n",
    "vocab = make_vocab('/Users/feismacbookpro/Desktop/INFX575/HW2/alltext.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(X): <type 'numpy.ndarray'>\n",
      "shape: (11, 521)\n",
      "\n",
      "type(vocab): <type 'list'>\n",
      "len(vocab): 544\n",
      "\n",
      "type(titles): <type 'list'>\n",
      "len(titles): 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# document-term matrix\n",
    "#http://chrisstrelioff.ws/sandbox/2014/11/13/getting_started_with_latent_dirichlet_allocation_in_python.html\n",
    "# X = lda.datasets.load_reuters()\n",
    "X = np.array(d1)\n",
    "print(\"type(X): {}\".format(type(X)))\n",
    "print(\"shape: {}\\n\".format(X.shape))\n",
    "\n",
    "# vocab = lda.datasets.load_reuters_vocab()\n",
    "print(\"type(vocab): {}\".format(type(vocab)))\n",
    "print(\"len(vocab): {}\\n\".format(len(vocab)))\n",
    "\n",
    "# # titles for each story\n",
    "# titles = lda.datasets.load_reuters_titles()\n",
    "titles = text\n",
    "print(\"type(titles): {}\".format(type(titles)))\n",
    "print(\"len(titles): {}\\n\".format(len(titles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc id: 3 word id: 1\n",
      "-- count: 0\n",
      "-- word : four\n",
      "-- doc  : ~~ 1. A perineum protecting device for protecting the perineum of males while riding a bicycle to prevent damage to the penile artery, said device comprising: a panel, said panel having a front edge, a back edge, a first side edge and a back side edge; and  a securing means for removably abutting said panel against the perineum; said securing means comprising:  a first loop member, said first loop member having a first end and a second end, said first end being securely attached to said first side edge and positioned generally adjacent to said front edge, said second end being securely attached to said first side edge and positioned generally adjacent to said back edge; and  a second loop member, said second loop member having a first end and a second end, said first end being securely attached to said second side edge and positioned generally adjacent to said front edge, said second end being securely attached to said second side edge and positioned generally adjacent to said back edge.  2. The perineum protecting device as in  claim 1 , wherein said panel has a middle portion, said middle portion comprising a cushioning material. 3. The perineum protecting device as in  claim 1 , wherein said panel has a height generally between 1 inch and 2 inches. 4. The perineum protecting device as in  claim 2 , wherein said cushioning material comprises a foamed elastomeric material. 5. The perineum protecting device as in  claim 2 , wherein said middle portion of said panel is generally enclosed in a covering membrane. 6. The perineum protecting device as in  claim 5 , wherein said covering member of said panel has a slit extending therethrough, wherein said middle portion may be selectively extended through said slit and be removed from said covering membrane. 7. The perineum protecting device as in  claim 5 , wherein said covering membrane comprises a cloth material, said panel having a width generally between 1| inches and 3 inches, a length generally between 3 inches and 5 inches and a height generally between 1 inch and 2 inches. 8. The perineum protecting device as in  claim 1 , wherein each of said first and second loop members comprises an elongate flexible member, said elongate flexible member comprising an elastomeric material. 9. A perineum protecting device for protecting the perineum of males while riding a bicycle to prevent damage to the penile artery, said device comprising: a panel, said panel having a front edge, a back edge, a first side edge and a back side edge, said panel having a middle portion, said middle portion comprising a cushioning material, said cushioning material comprising a foamed elastomeric material, said middle portion being generally enclosed in a covering membrane, said covering member having a slit extending therethrough, said slit being generally positioned adjacent to said front edge of said panel and orientated generally parallel to said front edge, wherein said middle portion may be selectively extended through said slit and be removed from said covering membrane, said covering membrane comprising a cloth material, said panel having a width generally between 1| inches and 3 inches, a length generally between 3 inches and 5 inches and a height generally between 1 inch and 2 inches;  a securing means for removably abutting said panel against the perineum, said securing means comprising;  a first loop member, said first loop member having a first end and a second end, said first end being securely attached to said first side edge and positioned generally adjacent to said front edge, said second end being securely attached to said first side edge and positioned generally adjacent to said back edge;  a second loop member, said second loop member having a first end and a second end, said first end being securely attached to said second side edge and positioned generally adjacent to said front edge, said second end being securely attached to said second side edge and positioned generally adjacent to said back edge; and  each of said first and second loop members comprising an elongate flexible member, said elongate flexible member comprising an elastomeric material.  10. A perineum protecting device for protecting the perineum of males while riding a bicycle to prevent damage to the penile artery, said device comprising: a panel having a front edge, a back edge, a first side edge and a back side edge; and  a securing means for removably holding said panel against the perineum; said securing means comprising:  a first loop member having a first end and a second end, said first end being attached to said first side edge and positioned generally adjacent to said front edge, said second end being attached to said first side edge and positioned generally adjacent to said back edge; and  a second loop member having a first end and a second end, said first end being attached to said second side edge and positioned generally adjacent to said front edge, said second end being attached to said second side edge and positioned generally adjacent to said back edge.  11. The perineum protecting device as in  claim 10 , wherein said panel has a middle portion comprising a cushioning material. 12. The perineum protecting device as in  claim 10 , wherein said panel has a height generally between 1 inch and 2 inches. 13. The perineum protecting device as in  claim 10 , wherein said cushioning material comprises a foamed elastomeric material. 14. The perineum protecting device as in  claim 11 , wherein said middle portion of said panel is generally enclosed in a covering membrane. 15. The perineum protecting device as in  claim 14 , wherein said covering member of said panel has a slit extending therethrough, and wherein said middle portion may be selectively extended through said slit and be removed from said covering membrane. 16. The perineum protecting device as in  claim 10 , wherein each of said first and second loop members comprises an elongate flexible member, said elongate flexible member comprising an elastomeric material.\n"
     ]
    }
   ],
   "source": [
    "doc_id = 3\n",
    "word_id = 1\n",
    "\n",
    "print(\"doc id: {} word id: {}\".format(doc_id, word_id))\n",
    "print(\"-- count: {}\".format(X[doc_id, word_id]))\n",
    "print(\"-- word : {}\".format(vocab[word_id]))\n",
    "print(\"-- doc  : {}\".format(titles[doc_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(topic_word): <type 'numpy.ndarray'>\n",
      "shape: (5, 521)\n"
     ]
    }
   ],
   "source": [
    "model = lda.LDA(n_topics=5, n_iter=500, random_state=1)\n",
    "model.fit(X)\n",
    "\n",
    "topic_word = model.topic_word_\n",
    "print(\"type(topic_word): {}\".format(type(topic_word)))\n",
    "print(\"shape: {}\".format(topic_word.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: 0 sum: 1.0\n",
      "topic: 1 sum: 1.0\n",
      "topic: 2 sum: 1.0\n",
      "topic: 3 sum: 1.0\n",
      "topic: 4 sum: 1.0\n"
     ]
    }
   ],
   "source": [
    "for n in range(5):\n",
    "    sum_pr = sum(topic_word[n,:])\n",
    "    print(\"topic: {} sum: {}\".format(n, sum_pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Topic 0\n",
      "- aperture contact scrubbing secure middle\n",
      "*Topic 1\n",
      "- rotated claim secure trunk relative\n",
      "*Topic 2\n",
      "- base layer internal conducting extends\n",
      "*Topic 3\n",
      "- claim flexible late rotated spacers\n",
      "*Topic 4\n",
      "- rotated spraying mixed feet ones\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n+1):-1]\n",
    "    print('*Topic {}\\n- {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Discover Culture Holes among 2 groups of toy documents\n",
    "\n",
    "# make text for each group\n",
    "toyDIR = '/Users/feismacbookpro/Desktop/INFX575/HW3/toy/'\n",
    "locs = ['doc1.txt', 'doc2.txt', 'doc3.txt', 'doc4.txt', 'doc5.txt']\n",
    "\n",
    "# group1 is doc1 and doc2\n",
    "group1 = []\n",
    "t = open(toyDIR + locs[0])\n",
    "for word in t.read().split():\n",
    "    group1.append(word)\n",
    "\n",
    "t = open(toyDIR + locs[1])\n",
    "for word in t.read().split():\n",
    "    group1.append(word)\n",
    "\n",
    "# group2 is doc3 to doc5\n",
    "group2 = []\n",
    "t = open(toyDIR + locs[2])\n",
    "for word in t.read().split():\n",
    "    group2.append(word)\n",
    "\n",
    "t = open(toyDIR + locs[3])\n",
    "for word in t.read().split():\n",
    "    group2.append(word)\n",
    "    \n",
    "t = open(toyDIR + locs[4])\n",
    "for word in t.read().split():\n",
    "    group2.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.199129551664186, 12.356285321583119)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# for H_x for each document\n",
    "# entrophy = []\n",
    "# for i in range(len(toy['docs'])):\n",
    "#     count = Counter(toy['docs'][i].split())\n",
    "#     vocab = list(set(toy['docs'][i].split()))\n",
    "#     H_x = 0\n",
    "#     for word in vocab:\n",
    "#         p_x = count[word]/len(vocab)\n",
    "#         if p_x > 0:\n",
    "#             H_x += - p_x * math.log(p_x, 2)\n",
    "#     entrophy.append(H_x)\n",
    "# entrophy\n",
    "\n",
    "# for H_x for each group\n",
    "def shannon(group):\n",
    "    entrophy = []\n",
    "    count = Counter(group)\n",
    "    vocab = list(set(group))\n",
    "    H_x = 0\n",
    "    for word in vocab:\n",
    "        p_x = count[word]/len(vocab)\n",
    "        if p_x > 0:\n",
    "            H_x += - p_x * math.log(p_x, 2)\n",
    "    entrophy.append(H_x)\n",
    "    return entrophy\n",
    "\n",
    "H1 = shannon(group1)\n",
    "H2 = shannon(group2)\n",
    "\n",
    "# for Q(pi||pj)\n",
    "\n",
    "# for corpus code book S\n",
    "text_all = []\n",
    "for loc in locs:\n",
    "    f = open(toyDIR + loc)\n",
    "    for word in f.read().split():\n",
    "        text_all.append(word)\n",
    "text_all\n",
    "\n",
    "# function to calculate Q(pi||pj)\n",
    "def q_entrophy(text_all, group1, group2):\n",
    "    count1 = Counter(group1)\n",
    "    vocab1 = list(set(group1))\n",
    "    count2 = Counter(group2)\n",
    "    vocab2 = list(set(group2))\n",
    "    s_count = Counter(text_all)\n",
    "    s_vocab = list(set(text_all))\n",
    "    q = 0\n",
    "    for w in vocab1:\n",
    "        p_1 = count1[w]/len(vocab1)\n",
    "        p_2 = count2[w]/len(vocab2)\n",
    "        s_x = s_count[w]/len(s_vocab)\n",
    "        p_s1 = 0.9 * p_1 + 0.1 * s_x\n",
    "        p_s2 = 0.9 * p_2 + 0.1 * s_x\n",
    "        q += - p_s1 * math.log(p_s2, 2)\n",
    "    return q\n",
    "\n",
    "q_ij = q_entrophy(text_all, group1, group2)\n",
    "q_ji = q_entrophy(text_all, group2, group1)\n",
    "\n",
    "q_ij, q_ji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3.592107220331598], [5.491813196968491])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H1, H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43810836232030315, 0.4444550327253908)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_ij = H1[0] / q_ij\n",
    "E_ji = H2[0] / q_ji\n",
    "\n",
    "E_ij, E_ji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5618916376796969, 0.5555449672746092)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_ij = 1 - E_ij\n",
    "C_ji = 1 - E_ji\n",
    "\n",
    "C_ij, C_ji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5618916376796969"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def JD(text_all, group1, group2):\n",
    "    H1 = shannon(group1)\n",
    "    q_ij = q_entrophy(text_all, group1, group2)\n",
    "    E_ij = H1[0] / q_ij\n",
    "    C_ij = 1 - E_ij\n",
    "    return C_ij\n",
    "\n",
    "C_ij = JD(text_all, group1, group2)\n",
    "C_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/feismacbookpro/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.py:654: DeprecationWarning: The charset_error parameter is deprecated as of version 0.14 and will be removed in 0.16. Use decode_error instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airplane</th>\n",
       "      <th>apples</th>\n",
       "      <th>bird</th>\n",
       "      <th>black</th>\n",
       "      <th>blue</th>\n",
       "      <th>burning</th>\n",
       "      <th>carrot</th>\n",
       "      <th>cat</th>\n",
       "      <th>celery</th>\n",
       "      <th>chases</th>\n",
       "      <th>...</th>\n",
       "      <th>eggplant</th>\n",
       "      <th>flying</th>\n",
       "      <th>honeydew</th>\n",
       "      <th>pears</th>\n",
       "      <th>processes</th>\n",
       "      <th>raspberries</th>\n",
       "      <th>sky</th>\n",
       "      <th>strawberries</th>\n",
       "      <th>tomato</th>\n",
       "      <th>watermelon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc1.txt</th>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2.txt</th>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc3.txt</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc4.txt</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc5.txt</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td>...</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          airplane  apples  bird  black  blue  burning  carrot  cat  celery  \\\n",
       "doc1.txt         0       1     0      0     0        0       0    0       0   \n",
       "doc2.txt         0       1     0      0     0        0       1    0       1   \n",
       "doc3.txt         1       0     1      0     0        0       0    0       0   \n",
       "doc4.txt         0       0     0      1     1        1       0    0       0   \n",
       "doc5.txt         0       0     0      0     0        0       0    1       0   \n",
       "\n",
       "          chases   ...    eggplant  flying  honeydew  pears  processes  \\\n",
       "doc1.txt       0   ...           0       0         1      1          0   \n",
       "doc2.txt       0   ...           1       0         0      0          0   \n",
       "doc3.txt       0   ...           0       2         0      0          0   \n",
       "doc4.txt       0   ...           0       0         0      0          0   \n",
       "doc5.txt       1   ...           0       0         0      0          1   \n",
       "\n",
       "          raspberries  sky  strawberries  tomato  watermelon  \n",
       "doc1.txt            1    0             1       0           1  \n",
       "doc2.txt            0    0             0       1           0  \n",
       "doc3.txt            0    3             0       0           0  \n",
       "doc4.txt            0    1             0       0           0  \n",
       "doc5.txt            0    0             0       0           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try LDA on the toy set\n",
    "\n",
    "d2 = fn_tdm_df(docs = fn_CorpusFromDIR(toyDIR)['docs'],\n",
    "          xColNames = fn_CorpusFromDIR(toyDIR)['ColNames'], \n",
    "          stop_words='english', charset_error = 'replace')\n",
    "d2 = d2.T\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toyVocab = list(set(text_all))\n",
    "\n",
    "X = np.array(d2)\n",
    "model = lda.LDA(n_topics=2, n_iter=500, random_state=1)\n",
    "model.fit(X)\n",
    "\n",
    "topic_word = model.topic_word_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Topic 0\n",
      "- is computer watermelon honeydew cat\n",
      "*Topic 1\n",
      "- sometimes strawberries burning flying carrot\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(toyVocab)[np.argsort(topic_dist)][:-(n+1):-1]\n",
    "    print('*Topic {}\\n- {}'.format(i, ' '.join(topic_words)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
